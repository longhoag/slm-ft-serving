[tool.poetry]
name = "slm-ft-serving"
version = "0.1.0"
description = "vLLM serving infrastructure for fine-tuned Llama 3.1 8B medical IE model"
authors = ["Long Hoang <longhhoang1202@gmail.com>"]
readme = "README.md"
package-mode = false

[tool.poetry.scripts]
deploy = "scripts.deploy:main"

[tool.poetry.dependencies]
python = "^3.10"
boto3 = "^1.35.0"
loguru = "^0.7.2"
pyyaml = "^6.0.2"

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
black = "^24.0.0"
ruff = "^0.6.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 100
target-version = ['py310']

[tool.ruff]
line-length = 100
target-version = "py310"
